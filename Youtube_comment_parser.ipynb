{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ahmedshahriar/youtube-comment-scraper/blob/main/Youtube_comment_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"74Cn074TFXtB"},"source":["# Download Comments from Youtube videos\n","\n","GitHub Repo : [youtube-comment-scraper](https://github.com/ahmedshahriar/youtube-comment-scraper)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ijjbm-fAvC3","outputId":"a6088287-9153-4d39-c13e-627f4b145278","trusted":true},"outputs":[],"source":["\"\"\"\n","By Ahmed Shahriar Sakib\n","GitHub : https://github.com/ahmedshahriar\n","\n","The script is based on https://github.com/egbertbouman/youtube-comment-downloader\n","\n","By default the script will download most recent 100 comments\n","You can change the default filter (line 33 onwards)\n","Variables :\n","COMMENT_LIMIT : How many comments you want to download \n","SORT_BY_POPULAR : filter comments by popularity (0 for True , 1 for false)\n","SORT_BY_RECENT : filter comments by recently posted (0 for True , 1 for false)\n","\"\"\"\n","\n","import pandas as pd\n","import json\n","import os\n","import sys\n","import re\n","import time\n","\n","import requests\n","\n","# pandas dataframe display configuration\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","YOUTUBE_COMMENTS_AJAX_URL = 'https://www.youtube.com/comment_service_ajax'\n","\n","USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n","# csv file name\n","FILE_NAME = 'ytb_comments.csv'\n","filename_increment = 1\n","# set parameters\n","# filter comments by popularity or recent, 0:False, 1:True\n","SORT_BY_POPULAR = 0\n","# default recent\n","SORT_BY_RECENT = 1\n","# set comment limit\n","COMMENT_LIMIT = 1000\n","\n","YT_CFG_RE = r'ytcfg\\.set\\s*\\(\\s*({.+?})\\s*\\)\\s*;'\n","YT_INITIAL_DATA_RE = r'(?:window\\s*\\[\\s*[\"\\']ytInitialData[\"\\']\\s*\\]|ytInitialData)\\s*=\\s*({.+?})\\s*;\\s*(?:var\\s+meta|</script|\\n)'\n","\n","\n","def regex_search(text, pattern, group=1, default=None):\n","    match = re.search(pattern, text)\n","    return match.group(group) if match else default\n","\n","\n","def ajax_request(session, endpoint, ytcfg, retries=5, sleep=20):\n","    url = 'https://www.youtube.com' + endpoint['commandMetadata']['webCommandMetadata']['apiUrl']\n","    \n","    data = {'context': ytcfg['INNERTUBE_CONTEXT'],\n","            'continuation': endpoint['continuationCommand']['token']}\n","\n","    for _ in range(retries):\n","        response = session.post(url, params={'key': ytcfg['INNERTUBE_API_KEY']}, json=data)\n","        if response.status_code == 200:\n","            return response.json()\n","        if response.status_code in [403, 413]:\n","            return {}\n","        else:\n","            time.sleep(sleep)\n","\n","\n","def download_comments(YOUTUBE_VIDEO_URL, sort_by=SORT_BY_RECENT, language=None, sleep=0.1):\n","    session = requests.Session()\n","    session.headers['User-Agent'] = USER_AGENT\n","    response = session.get(YOUTUBE_VIDEO_URL)\n","\n","    if 'uxe=' in response.request.url:\n","        session.cookies.set('CONSENT', 'YES+cb', domain='.youtube.com')\n","        response = session.get(YOUTUBE_VIDEO_URL)\n","\n","    html = response.text\n","    ytcfg = json.loads(regex_search(html, YT_CFG_RE, default=''))\n","    if not ytcfg:\n","        return # Unable to extract configuration\n","    if language:\n","        ytcfg['INNERTUBE_CONTEXT']['client']['hl'] = language\n","\n","    data = json.loads(regex_search(html, YT_INITIAL_DATA_RE, default=''))\n","\n","    section = next(search_dict(data, 'itemSectionRenderer'), None)\n","    renderer = next(search_dict(section, 'continuationItemRenderer'), None) if section else None\n","    if not renderer:\n","        # Comments disabled?\n","        return\n","\n","    needs_sorting = sort_by != SORT_BY_POPULAR\n","    continuations = [renderer['continuationEndpoint']]\n","    while continuations:\n","        continuation = continuations.pop()\n","        response = ajax_request(session, continuation, ytcfg)\n","\n","        if not response:\n","            break\n","        if list(search_dict(response, 'externalErrorMessage')):\n","            raise RuntimeError('Error returned from server: ' + next(search_dict(response, 'externalErrorMessage')))\n","\n","        if needs_sorting:\n","            sort_menu = next(search_dict(response, 'sortFilterSubMenuRenderer'), {}).get('subMenuItems', [])\n","            if sort_by < len(sort_menu):\n","                continuations = [sort_menu[sort_by]['serviceEndpoint']]\n","                needs_sorting = False\n","                continue\n","            raise RuntimeError('Failed to set sorting')\n","\n","        actions = list(search_dict(response, 'reloadContinuationItemsCommand')) + \\\n","                  list(search_dict(response, 'appendContinuationItemsAction'))\n","        for action in actions:\n","            for item in action.get('continuationItems', []):\n","                if action['targetId'] == 'comments-section':\n","                    # Process continuations for comments and replies.\n","                    continuations[:0] = [ep for ep in search_dict(item, 'continuationEndpoint')]\n","                if action['targetId'].startswith('comment-replies-item') and 'continuationItemRenderer' in item:\n","                    # Process the 'Show more replies' button\n","                    continuations.append(next(search_dict(item, 'buttonRenderer'))['command'])\n","\n","        for comment in reversed(list(search_dict(response, 'commentRenderer'))):\n","            yield {'cid': comment['commentId'],\n","                   'text': ''.join([c['text'] for c in comment['contentText'].get('runs', [])]),\n","                   'time': comment['publishedTimeText']['runs'][0]['text'],\n","                   'author': comment.get('authorText', {}).get('simpleText', ''),\n","                   'channel': comment['authorEndpoint']['browseEndpoint'].get('browseId', ''),\n","                   'votes': comment.get('voteCount', {}).get('simpleText', '0'),\n","                   'photo': comment['authorThumbnail']['thumbnails'][-1]['url'],\n","                   'heart': next(search_dict(comment, 'isHearted'), False)}\n","\n","        time.sleep(sleep)\n","\n","\n","def search_dict(partial, search_key):\n","    stack = [partial]\n","    while stack:\n","        current_item = stack.pop()\n","        if isinstance(current_item, dict):\n","            for key, value in current_item.items():\n","                if key == search_key:\n","                    yield value\n","                else:\n","                    stack.append(value)\n","        elif isinstance(current_item, list):\n","            for value in current_item:\n","                stack.append(value)\n","\n","\n","def main(url):\n","    df_comment = pd.DataFrame()\n","    try:\n","        youtube_url = url\n","        limit = COMMENT_LIMIT\n","\n","        print('Downloading Youtube comments for video:', youtube_url)\n","\n","        count = 0\n","\n","        start_time = time.time()\n","\n","        for comment in download_comments(youtube_url,sort_by=SORT_BY_POPULAR):\n","\n","            df_comment = df_comment.append(comment, ignore_index=True)  \n","\n","            # comments overview\n","            comment_json = json.dumps(comment, ensure_ascii=False)\n","            #print(comment_json)\n","\n","            count += 1\n","\n","            if limit and count >= limit:\n","                break\n","\n","        #print(\"DataFrame Shape: \",df_comment.shape,\"\\nComment DataFrame: \", df_comment)\n","\n","        #this_filename = FILE_NAME + filename_increment\n","        df_comment['video_url'] = youtube_url\n","\n","        if not os.path.isfile(FILE_NAME):\n","            df_comment.to_csv(FILE_NAME, encoding='utf-8', index=False)\n","        else:  # else it exists so append without writing the header\n","            df_comment.to_csv(FILE_NAME, mode='a', encoding='utf-8', index=False, header=False)\n","\n","        print('\\n[{:.2f} seconds] Done!'.format(time.time() - start_time))\n","    \n","\n","    except Exception as e:\n","        print('Error:', str(e))\n","        sys.exit(1)                            \n","\n","\n","# dumping youtube comments\n","\n","\"\"\" \n","1. Dump comments to a csv  from a single video\n","\n","\"\"\"\n","# youtube_URL = 'https://www.youtube.com/watch?v=fucUDHaZ0Ug'\n","# main(youtube_URL)\n","\n","\"\"\"\n","2. Dump comments to a csv by parsing links from a csv with video links\n","\n","Example -\n","Create a csv with one column titled 'link'\n","a sample is given below\n","\n","'ytb_video_list.csv'\n","\n","link\n","https://www.youtube.com/watch?v=-t_uhBBDbA4\n","https://www.youtube.com/watch?v=75vjjRza7IU\n","https://www.youtube.com/watch?v=j6dmaPzOBHY\n","https://www.youtube.com/watch?v=Yj2efyQV1RI\n","https://www.youtube.com/watch?v=HV652F7U6Qs\n","https://www.youtube.com/watch?v=47iXEucg3eo\n","https://www.youtube.com/watch?v=ofHXBLEE3TQ\n","https://www.youtube.com/watch?v=X6lGqSfVRT8\n","https://www.youtube.com/watch?v=a_-z9FhGBrE\n","https://www.youtube.com/watch?v=wTUM_4cVlE4\n","\n","\n","\"\"\"\n","df_video_list = pd.read_csv('ytb_video_list.csv')\n","print(df_video_list['link'].map(lambda x: main(x)))\n","# print(main(pd.read_csv('ytb_video_list.csv')['link']))\n","\n","\n","\"\"\"\n","3. Dump to a csv from a a list with video links\n","\"\"\"\n","# ytb_video_list = ['https://www.youtube.com/watch?v=Y2jyjfcp1as',\n","#                   'https://www.youtube.com/watch?v=GNZBSZD16cY',\n","#                   'https://www.youtube.com/watch?v=36m1o-tM05g',\n","#                   'https://www.youtube.com/watch?v=7TXEZ4tP06c']\n","\n","# for video_link in ytb_video_list:\n","#     main(video_link)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQpFQMAxSxzS","outputId":"226b2e0f-59d1-4fac-ced2-39e5329df442"},"outputs":[],"source":["df_comment = pd.read_csv('/content/ytb_comments.csv')\n","df_comment.shape"]}],"metadata":{"colab":{"collapsed_sections":[],"include_colab_link":true,"name":"Youtube_comment_parser.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
